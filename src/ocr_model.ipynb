{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!sudo apt-get update\n","!sudo apt install tesseract-ocr\n","!pip install pytesseract"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FfsqmcYw82Su","executionInfo":{"status":"ok","timestamp":1710999412356,"user_tz":-330,"elapsed":19176,"user":{"displayName":"Suhail Hussain","userId":"01084270938039820503"}},"outputId":"ffb73c56-d6c2-4962-f553-87b03f1cdb02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [51.0 kB]\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:9 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,037 kB]\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,356 kB]\n","Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,619 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,074 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,898 kB]\n","Fetched 9,267 kB in 3s (2,844 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 44 not upgraded.\n","Need to get 4,816 kB of archives.\n","After this operation, 15.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n","Fetched 4,816 kB in 2s (1,993 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 121752 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n","Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n","Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr (4.1.1-2.1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.10\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PpMwBWMp6jA7","executionInfo":{"status":"ok","timestamp":1710999416890,"user_tz":-330,"elapsed":4542,"user":{"displayName":"Suhail Hussain","userId":"01084270938039820503"}},"outputId":"954808c0-0448-4f97-80d3-409687b08b9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"]}],"source":["!pip install opencv-python-headless"]},{"cell_type":"code","source":["!wget https://github.com/oyyd/frozen_east_text_detection.pb/raw/master/frozen_east_text_detection.pb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58MelpSo865N","executionInfo":{"status":"ok","timestamp":1710999422469,"user_tz":-330,"elapsed":5583,"user":{"displayName":"Suhail Hussain","userId":"01084270938039820503"}},"outputId":"2dd6e629-ba94-402b-87e4-27a013e6bd90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-21 05:36:55--  https://github.com/oyyd/frozen_east_text_detection.pb/raw/master/frozen_east_text_detection.pb\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/oyyd/frozen_east_text_detection.pb/master/frozen_east_text_detection.pb [following]\n","--2024-03-21 05:36:55--  https://raw.githubusercontent.com/oyyd/frozen_east_text_detection.pb/master/frozen_east_text_detection.pb\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 96662756 (92M) [application/octet-stream]\n","Saving to: ‘frozen_east_text_detection.pb’\n","\n","frozen_east_text_de 100%[===================>]  92.18M  70.0MB/s    in 1.3s    \n","\n","2024-03-21 05:37:01 (70.0 MB/s) - ‘frozen_east_text_detection.pb’ saved [96662756/96662756]\n","\n"]}]},{"cell_type":"code","source":["import os\n","import time\n","import re\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pytesseract\n","from imutils.object_detection import non_max_suppression\n","from PIL import Image\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt"],"metadata":{"id":"uQ6UNFX56vws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def display_image(img):\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"jvAQ3ReV60xO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","for filename in uploaded.keys():\n","  print('User uploaded file \"{name}\" with {length} bytes'.format(name=filename, length=len(uploaded[filename])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"R0PB8XwA9oAP","executionInfo":{"status":"ok","timestamp":1710999600817,"user_tz":-330,"elapsed":96905,"user":{"displayName":"Suhail Hussain","userId":"01084270938039820503"}},"outputId":"c9c83078-eca0-4873-c6a8-098d0c16e698"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c6879e7a-43e9-4107-9c69-fc2cd3137f5c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c6879e7a-43e9-4107-9c69-fc2cd3137f5c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving test_images.zip to test_images.zip\n","User uploaded file \"test_images.zip\" with 1304770 bytes\n"]}]},{"cell_type":"code","source":["zip_file_path = '/content/test_images.zip'\n","extraction_directory = '/content/test_images/'\n","\n","!unzip \"{zip_file_path}\" -d \"{extraction_directory}\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_psm4Rt6-1L","executionInfo":{"status":"ok","timestamp":1710999604564,"user_tz":-330,"elapsed":1352,"user":{"displayName":"Suhail Hussain","userId":"01084270938039820503"}},"outputId":"6c2be0d0-5187-468a-c12a-eb0aafe75f69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/test_images.zip\n","  inflating: /content/test_images/img_annot.csv  \n","  inflating: /content/test_images/test_images/00bedd5c2fbf2dff.jpg  \n","  inflating: /content/test_images/test_images/00c7f84d61adce05.jpg  \n","  inflating: /content/test_images/test_images/03a1e7cf965c52c3.jpg  \n","  inflating: /content/test_images/test_images/0c2b594e8d66de4c.jpg  \n"]}]},{"cell_type":"code","source":["SAVED_MODEL_PATH = 'https://tfhub.dev/captain-pool/esrgan-tf2/1'"],"metadata":{"id":"W7vRBCmn4DtE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Masking Layer"],"metadata":{"id":"6kirExYb25Hg"}},{"cell_type":"code","source":["def post_process(orig, scores, geometry, confThreshold=0.5, nmsThreshold=0.4, rW=1, rH=1):\n","    (rects, confidences) = decode_predictions(scores, geometry, confThreshold)\n","\n","    # Apply non-maxima suppression to suppress weak, overlapping bounding boxes\n","    boxes = non_max_suppression(np.array(rects), probs=confidences, overlapThresh=nmsThreshold)\n","\n","\n","    mask = np.zeros(orig.shape[:2], dtype='uint8')\n","\n","    padding = 10  # Adjust padding as needed\n","\n","    for (startX, startY, endX, endY) in boxes:\n","        # Apply padding around each bounding box and ensure the coordinates are within image bounds\n","        p_startX = max(0, int(startX * rW ) - padding )\n","        p_startY = max(0, int(startY * rH ) - padding)\n","        p_endX = min(orig.shape[1] -1 , int( endX * rW ) + padding )\n","        p_endY = min(orig.shape[0] -1 , int( endY * rH ) + padding )\n","\n","        # Draw white rectangles on the mask for each bounding box (with padding)\n","        cv2.rectangle(mask, (p_startX, p_startY), (p_endX, p_endY), 255, -1)\n","\n","\n","    # Apply the mask to the original image\n","    masked_image = cv2.bitwise_and(orig, orig, mask=mask)\n","\n","    return masked_image"],"metadata":{"id":"HI2MMB3wNy3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decode_predictions(scores, geometry, confThreshold=0.5):\n","    # Grab the number of rows and columns from the scores volume, then\n","    # initialize our set of bounding box rectangles and corresponding\n","    # confidence scores\n","    (numRows, numCols) = scores.shape[2:4]\n","    rects = []\n","    confidences = []\n","\n","    # Loop over the number of rows\n","    for y in range(0, numRows):\n","        # Extract the scores (probabilities), followed by the\n","        # geometrical data used to derive potential bounding box\n","        # coordinates that surround text\n","        scoresData = scores[0, 0, y]\n","        xData0 = geometry[0, 0, y]\n","        xData1 = geometry[0, 1, y]\n","        xData2 = geometry[0, 2, y]\n","        xData3 = geometry[0, 3, y]\n","        anglesData = geometry[0, 4, y]\n","\n","        # Loop over the number of columns\n","        for x in range(0, numCols):\n","            # If our score does not have sufficient probability,\n","            # ignore it\n","            if scoresData[x] < confThreshold:\n","                continue\n","\n","            # Compute the offset factor as our resulting feature\n","            # maps will be 4x smaller than the input image\n","            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n","\n","            # Extract the rotation angle for the prediction and\n","            # compute the sin and cosine\n","            angle = anglesData[x]\n","            cos = np.cos(angle)\n","            sin = np.sin(angle)\n","\n","            # Use the geometry volume to derive the width and height\n","            # of the bounding box\n","            h = xData0[x] + xData2[x]\n","            w = xData1[x] + xData3[x]\n","\n","            # Compute both the starting and ending (x, y)-coordinates\n","            # for the text prediction bounding box\n","            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n","            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n","            startX = int(endX - w)\n","            startY = int(endY - h)\n","\n","            # Add the bounding box coordinates and probability score\n","            # to our respective lists\n","            rects.append((startX, startY, endX, endY))\n","            confidences.append(scoresData[x])\n","\n","    # Return a tuple of the bounding boxes and associated confidences\n","    return (rects, confidences)\n"],"metadata":{"id":"d5fe6tc28MNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##CNN Model for applying masking around the text\n","def detect_text_east(image_path):\n","    # Load image\n","    image = cv2.imread(image_path)\n","    orig = image.copy()\n","    (Ori_H, Ori_W) = image.shape[:2]\n","\n","    # Set the new width and height and then determine the ratio in change\n","    (newW, newH) = (320, 320)\n","    rW = Ori_W / float(newW)\n","    rH = Ori_H / float(newH)\n","\n","    # Resize the image and grab the new image dimensions\n","    image = cv2.resize(image, (newW, newH))\n","    (H, W) = image.shape[:2]\n","\n","    # Define the two output layer names for the EAST detector model\n","    layerNames = [\n","        \"feature_fusion/Conv_7/Sigmoid\",\n","        \"feature_fusion/concat_3\"\n","    ]\n","\n","    # Load the pre-trained EAST text detector\n","    net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n","\n","    # Construct a blob from the image and then perform a forward pass\n","    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n","                                 (123.68, 116.78, 103.94), swapRB=True, crop=False)\n","    net.setInput(blob)\n","    (scores, geometry) = net.forward(layerNames)\n","\n","    rW = Ori_W / float(newW)\n","    rH = Ori_H / float(newH)\n","\n","    # Decode the predictions, then  apply non-maxima suppression to suppress weak, overlapping bounding boxes\n","    result_image = post_process(orig.copy(), scores, geometry, confThreshold=0.5, nmsThreshold=0.4, rW=rW, rH=rH)\n","    # Return the original image (for now)\n","    return result_image\n","\n"],"metadata":{"id":"9GnP8XjD7IO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# output_path = '/content/img_stage_1.jpg'\n","# cv2.imwrite(output_path, result_image)"],"metadata":{"id":"vvzzvB8sRQ96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#IMAGE_PATH = '/content/img_stage_1.jpg'\n","#IMAGE_PATH = '/content/test_images/00bedd5c2fbf2dff.jpg'\n"],"metadata":{"id":"vvDVC5vp1qeJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Super Sampling Layer"],"metadata":{"id":"4sx8yzOC20bP"}},{"cell_type":"code","source":["def preprocess_image(image_path):\n","    \"\"\"Loads image from path and preprocesses to make it model ready\n","        :image_path: Path to the image file\n","    \"\"\"\n","    hr_image = tf.image.decode_image(tf.io.read_file(image_path))\n","    # If PNG, remove the alpha channel. The model only supports\n","    # images with 3 color channels.\n","    if hr_image.shape[-1] == 4:\n","        hr_image = hr_image[...,:-1]\n","    hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 4) * 4\n","    hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n","    hr_image = tf.cast(hr_image, tf.float32)\n","    return tf.expand_dims(hr_image, 0)\n","\n","def save_image(image, filename):\n","    \"\"\"\n","    Saves unscaled Tensor Images.\n","    :image: 3D image tensor. [height, width, channels]\n","    :filename: Name of the file to save.\n","    \"\"\"\n","    if not isinstance(image, Image.Image):\n","        image = tf.clip_by_value(image, 0, 255)\n","        image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n","    image.save(filename)"],"metadata":{"id":"Y5aVWPWP1ysM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","def plot_image(image, title=\"\"):\n","    \"\"\"Plots images from image tensors.\n","      :image: 3D image tensor. [height, width, channels].\n","      :title: Title to display in the plot.\n","    \"\"\"\n","    image = np.asarray(image)\n","    image = tf.clip_by_value(image, 0, 255)\n","    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n","    plt.imshow(image)\n","    plt.axis(\"off\")\n","    plt.title(title)"],"metadata":{"id":"8D_DAfFR2DoS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = hub.load(SAVED_MODEL_PATH)"],"metadata":{"id":"HvssaSdu6u2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder_path = '/content/test_images/test_images/'"],"metadata":{"id":"uDv63K_W9anN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create output folder"],"metadata":{"id":"psYmfQkS3it8"}},{"cell_type":"code","source":["os.mkdir('/content/output/')"],"metadata":{"id":"rB9-qdHOCg6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipeline_dict = {}"],"metadata":{"id":"hTN4qnoxHugd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir(folder_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBO_zKFwiNxb","executionInfo":{"status":"ok","timestamp":1710999793090,"user_tz":-330,"elapsed":4,"user":{"displayName":"Suhail Hussain","userId":"01084270938039820503"}},"outputId":"9f3e9fc2-fa4b-4864-f309-ac985a9ef653"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['00c7f84d61adce05.jpg',\n"," '0c2b594e8d66de4c.jpg',\n"," '00bedd5c2fbf2dff.jpg',\n"," '03a1e7cf965c52c3.jpg']"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["for image_file_name in os.listdir(folder_path):\n","    image_name = image_file_name.split('.')[0]\n","    image_path = folder_path + image_file_name\n","\n","    if image_name is None or image_name == '':\n","      continue\n","\n","    print(f'IMAGE NAME: ', image_name)\n","    start = time.time()\n","\n","    result_image = detect_text_east(image_path)\n","    #display_image(result_image)\n","    output_path = f'/content/output/{image_name}_stage_1.jpg'\n","    status = cv2.imwrite(output_path, result_image)\n","\n","    ## SUPER RESOLUTION\n","    IMAGE_PATH = f'/content/output/{image_name}_stage_1.jpg'\n","    hr_image = preprocess_image(IMAGE_PATH)\n","    #plot_image(tf.squeeze(hr_image), title=\"Original Image\")\n","\n","    fake_image = model(hr_image)\n","    fake_image = tf.squeeze(fake_image)\n","\n","    #plot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\n","    save_image(tf.squeeze(fake_image), filename=f\"/content/output/{image_name}_stage_2.jpg\")\n","\n","    ##OCR\n","\n","    masked_image_path = f'/content/output/{image_name}_stage_2.jpg'\n","    #masked_image_path = '/content/test_images/00bedd5c2fbf2dff.jpg'\n","\n","    # Read the image using OpenCV (PyTesseract also works with PIL images)\n","    masked_image = cv2.imread(masked_image_path)\n","\n","    # Convert the image to RGB (PyTesseract expects images in RGB format)\n","    masked_image_rgb = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)\n","\n","    # Use PyTesseract to extract text\n","    extracted_text = pytesseract.image_to_string(masked_image_rgb)\n","\n","    words = extracted_text.split()\n","    words = [re.sub(r'[^\\w\\s]', '', word) for word in words]\n","\n","\n","    print(\"Time Taken: %f\" % (time.time() - start))\n","\n","    print('==================================')\n","    print(\"Extracted Text:\")\n","    print(words)\n","    pipeline_dict[image_name] = words\n","    print('===================================')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZGnOW0m-7lD","executionInfo":{"status":"ok","timestamp":1711000090255,"user_tz":-330,"elapsed":90616,"user":{"displayName":"Suhail Hussain","userId":"01084270938039820503"}},"outputId":"35b246eb-45b5-447c-826a-aa26254a07b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["IMAGE NAME:  00c7f84d61adce05\n","Time Taken: 24.691547\n","==================================\n","Extracted Text:\n","['fr', 'ret', 'Ef', 'ht']\n","===================================\n","IMAGE NAME:  0c2b594e8d66de4c\n","Time Taken: 27.638587\n","==================================\n","Extracted Text:\n","['', 'Bertolt', 'Brecht', '', 'Der', 'kaukasischd', 'Kreidekreis', '', 'edition', 'suhrkamp']\n","===================================\n","IMAGE NAME:  00bedd5c2fbf2dff\n","Time Taken: 19.321335\n","==================================\n","Extracted Text:\n","['E', 'TALK', 'IS', 'CHEAP', 'REALLY']\n","===================================\n","IMAGE NAME:  03a1e7cf965c52c3\n","Time Taken: 17.512483\n","==================================\n","Extracted Text:\n","['1assic', 'Sinat', 'ra', 'SEI', 'li', 'ae', '', '', 'Get', 'a', 'Kick', 'Out', 'of', 'hoy', 'They', 'Cant', 'Take', 'That', 'NEA', 'g', 'You', 'Make', 'Me', 'Feel', 'So', 'Young', 'Oey', 'iy', 'Fly', 'babi', 'Wit']\n","===================================\n"]}]},{"cell_type":"code","source":["#!rm -r /content/output/"],"metadata":{"id":"PoLIjZ_98MVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tesseract_dict = {}"],"metadata":{"id":"JnBttu6wH6iv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_file_name in os.listdir(folder_path):\n","    start = time.time()\n","\n","    image_name = image_file_name.split('.')[0]\n","    image_path = folder_path + image_file_name\n","\n","    print(f'Image Name: {image_name}')\n","\n","    if image_name is None or image_name == '':\n","      continue\n","    masked_image_path = image_path\n","    #masked_image_path = '/content/test_images/00bedd5c2fbf2dff.jpg'\n","\n","    # Read the image using OpenCV (PyTesseract also works with PIL images)\n","    masked_image = cv2.imread(masked_image_path)\n","\n","    # Convert the image to RGB (PyTesseract expects images in RGB format)\n","    masked_image_rgb = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)\n","\n","    # Use PyTesseract to extract text\n","    extracted_text = pytesseract.image_to_string(masked_image_rgb)\n","\n","    words = extracted_text.split()\n","    words = [re.sub(r'[^\\w\\s]', '', word) for word in words]\n","\n","    print(\"Time Taken: %f\" % (time.time() - start))\n","\n","    print('==================================')\n","    print(\"Extracted Text:\")\n","    print(words)\n","    print('===================================')\n","\n","    tesseract_dict[image_name] = words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a-prlc0Eki_","executionInfo":{"status":"ok","timestamp":1711000116308,"user_tz":-330,"elapsed":3235,"user":{"displayName":"Suhail Hussain","userId":"01084270938039820503"}},"outputId":"95e4e870-d1b2-4f2d-f1b8-84a26711f41d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image Name: 00c7f84d61adce05\n","Time Taken: 0.724563\n","==================================\n","Extracted Text:\n","[]\n","===================================\n","Image Name: 0c2b594e8d66de4c\n","Time Taken: 0.787491\n","==================================\n","Extracted Text:\n","['Bertolt', 'Brecht', 'Der', 'kaukasische', 'Kreidekreis', 'edition', 'suhrkamp', 'SV', 'sea', '2S']\n","===================================\n","Image Name: 00bedd5c2fbf2dff\n","Time Taken: 0.540817\n","==================================\n","Extracted Text:\n","['', 'VACANCY']\n","===================================\n","Image Name: 03a1e7cf965c52c3\n","Time Taken: 0.695706\n","==================================\n","Extracted Text:\n","['Classic', 'Sinatra', 'Come', 'Fly', 'With', 'Me', 'Petes', 'Ue', 'eee', 'eae', 'ace', 'Esty', 'SONY', '', 'le', 'ETS', 'aR', 'ETT', 'ae', 'His', '', 'TTS', 'Wis', 'meek', 'Te', 'They', 'Cant', 'Take', 'That', 'Away', 'fr', 'You', 'Make', 'Me', 'Feel', 'So', 'ome', 'FY', 'Wa']\n","===================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9FEejliOJvU6"},"execution_count":null,"outputs":[]}]}