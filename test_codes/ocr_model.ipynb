{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19176,
     "status": "ok",
     "timestamp": 1710999412356,
     "user": {
      "displayName": "Suhail Hussain",
      "userId": "01084270938039820503"
     },
     "user_tz": -330
    },
    "id": "FfsqmcYw82Su",
    "outputId": "ffb73c56-d6c2-4962-f553-87b03f1cdb02"
   },
   "outputs": [],
   "source": [
    "# !sudo apt-get update\n",
    "# !sudo apt install tesseract-ocr\n",
    "# !pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4542,
     "status": "ok",
     "timestamp": 1710999416890,
     "user": {
      "displayName": "Suhail Hussain",
      "userId": "01084270938039820503"
     },
     "user_tz": -330
    },
    "id": "PpMwBWMp6jA7",
    "outputId": "954808c0-0448-4f97-80d3-409687b08b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in c:\\users\\shurai\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.10.0.84)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\shurai\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opencv-python-headless) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5583,
     "status": "ok",
     "timestamp": 1710999422469,
     "user": {
      "displayName": "Suhail Hussain",
      "userId": "01084270938039820503"
     },
     "user_tz": -330
    },
    "id": "58MelpSo865N",
    "outputId": "2dd6e629-ba94-402b-87e4-27a013e6bd90"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2848011636.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    wget https://github.com/oyyd/frozen_east_text_detection.pb/raw/master/frozen_east_text_detection.pb\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "wget https://github.com/oyyd/frozen_east_text_detection.pb/raw/master/frozen_east_text_detection.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uQ6UNFX56vws"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m non_max_suppression\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvAQ3ReV60xO"
   },
   "outputs": [],
   "source": [
    "def display_image(img):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "executionInfo": {
     "elapsed": 96905,
     "status": "ok",
     "timestamp": 1710999600817,
     "user": {
      "displayName": "Suhail Hussain",
      "userId": "01084270938039820503"
     },
     "user_tz": -330
    },
    "id": "R0PB8XwA9oAP",
    "outputId": "c9c83078-eca0-4873-c6a8-098d0c16e698"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c6879e7a-43e9-4107-9c69-fc2cd3137f5c\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c6879e7a-43e9-4107-9c69-fc2cd3137f5c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test_images.zip to test_images.zip\n",
      "User uploaded file \"test_images.zip\" with 1304770 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with {length} bytes'.format(name=filename, length=len(uploaded[filename])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1352,
     "status": "ok",
     "timestamp": 1710999604564,
     "user": {
      "displayName": "Suhail Hussain",
      "userId": "01084270938039820503"
     },
     "user_tz": -330
    },
    "id": "Q_psm4Rt6-1L",
    "outputId": "6c2be0d0-5187-468a-c12a-eb0aafe75f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/test_images.zip\n",
      "  inflating: /content/test_images/img_annot.csv  \n",
      "  inflating: /content/test_images/test_images/00bedd5c2fbf2dff.jpg  \n",
      "  inflating: /content/test_images/test_images/00c7f84d61adce05.jpg  \n",
      "  inflating: /content/test_images/test_images/03a1e7cf965c52c3.jpg  \n",
      "  inflating: /content/test_images/test_images/0c2b594e8d66de4c.jpg  \n"
     ]
    }
   ],
   "source": [
    "zip_file_path = '/content/test_images.zip'\n",
    "extraction_directory = '/content/test_images/'\n",
    "\n",
    "!unzip \"{zip_file_path}\" -d \"{extraction_directory}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7vRBCmn4DtE"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = 'https://tfhub.dev/captain-pool/esrgan-tf2/1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kirExYb25Hg"
   },
   "source": [
    "Masking Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HI2MMB3wNy3q"
   },
   "outputs": [],
   "source": [
    "def post_process(orig, scores, geometry, confThreshold=0.5, nmsThreshold=0.4, rW=1, rH=1):\n",
    "    (rects, confidences) = decode_predictions(scores, geometry, confThreshold)\n",
    "\n",
    "    # Apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences, overlapThresh=nmsThreshold)\n",
    "\n",
    "\n",
    "    mask = np.zeros(orig.shape[:2], dtype='uint8')\n",
    "\n",
    "    padding = 10  # Adjust padding as needed\n",
    "\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # Apply padding around each bounding box and ensure the coordinates are within image bounds\n",
    "        p_startX = max(0, int(startX * rW ) - padding )\n",
    "        p_startY = max(0, int(startY * rH ) - padding)\n",
    "        p_endX = min(orig.shape[1] -1 , int( endX * rW ) + padding )\n",
    "        p_endY = min(orig.shape[0] -1 , int( endY * rH ) + padding )\n",
    "\n",
    "        # Draw white rectangles on the mask for each bounding box (with padding)\n",
    "        cv2.rectangle(mask, (p_startX, p_startY), (p_endX, p_endY), 255, -1)\n",
    "\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    masked_image = cv2.bitwise_and(orig, orig, mask=mask)\n",
    "\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5fe6tc28MNb"
   },
   "outputs": [],
   "source": [
    "def decode_predictions(scores, geometry, confThreshold=0.5):\n",
    "    # Grab the number of rows and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence scores\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    # Loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # Extract the scores (probabilities), followed by the\n",
    "        # geometrical data used to derive potential bounding box\n",
    "        # coordinates that surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        # Loop over the number of columns\n",
    "        for x in range(0, numCols):\n",
    "            # If our score does not have sufficient probability,\n",
    "            # ignore it\n",
    "            if scoresData[x] < confThreshold:\n",
    "                continue\n",
    "\n",
    "            # Compute the offset factor as our resulting feature\n",
    "            # maps will be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            # Extract the rotation angle for the prediction and\n",
    "            # compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # Use the geometry volume to derive the width and height\n",
    "            # of the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            # Compute both the starting and ending (x, y)-coordinates\n",
    "            # for the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            # Add the bounding box coordinates and probability score\n",
    "            # to our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "    # Return a tuple of the bounding boxes and associated confidences\n",
    "    return (rects, confidences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GnP8XjD7IO4"
   },
   "outputs": [],
   "source": [
    "##CNN Model for applying masking around the text\n",
    "def detect_text_east(image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    orig = image.copy()\n",
    "    (Ori_H, Ori_W) = image.shape[:2]\n",
    "\n",
    "    # Set the new width and height and then determine the ratio in change\n",
    "    (newW, newH) = (320, 320)\n",
    "    rW = Ori_W / float(newW)\n",
    "    rH = Ori_H / float(newH)\n",
    "\n",
    "    # Resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # Define the two output layer names for the EAST detector model\n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"\n",
    "    ]\n",
    "\n",
    "    # Load the pre-trained EAST text detector\n",
    "    net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "\n",
    "    # Construct a blob from the image and then perform a forward pass\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "                                 (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "    rW = Ori_W / float(newW)\n",
    "    rH = Ori_H / float(newH)\n",
    "\n",
    "    # Decode the predictions, then  apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    result_image = post_process(orig.copy(), scores, geometry, confThreshold=0.5, nmsThreshold=0.4, rW=rW, rH=rH)\n",
    "    # Return the original image (for now)\n",
    "    return result_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvzzvB8sRQ96"
   },
   "outputs": [],
   "source": [
    "# output_path = '/content/img_stage_1.jpg'\n",
    "# cv2.imwrite(output_path, result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvDVC5vp1qeJ"
   },
   "outputs": [],
   "source": [
    "#IMAGE_PATH = '/content/img_stage_1.jpg'\n",
    "#IMAGE_PATH = '/content/test_images/00bedd5c2fbf2dff.jpg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sx8yzOC20bP"
   },
   "source": [
    "Super Sampling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5aVWPWP1ysM"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads image from path and preprocesses to make it model ready\n",
    "        :image_path: Path to the image file\n",
    "    \"\"\"\n",
    "    hr_image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "    # If PNG, remove the alpha channel. The model only supports\n",
    "    # images with 3 color channels.\n",
    "    if hr_image.shape[-1] == 4:\n",
    "        hr_image = hr_image[...,:-1]\n",
    "    hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 4) * 4\n",
    "    hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n",
    "    hr_image = tf.cast(hr_image, tf.float32)\n",
    "    return tf.expand_dims(hr_image, 0)\n",
    "\n",
    "def save_image(image, filename):\n",
    "    \"\"\"\n",
    "    Saves unscaled Tensor Images.\n",
    "    :image: 3D image tensor. [height, width, channels]\n",
    "    :filename: Name of the file to save.\n",
    "    \"\"\"\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = tf.clip_by_value(image, 0, 255)\n",
    "        image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "    image.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8D_DAfFR2DoS"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_image(image, title=\"\"):\n",
    "    \"\"\"Plots images from image tensors.\n",
    "      :image: 3D image tensor. [height, width, channels].\n",
    "      :title: Title to display in the plot.\n",
    "    \"\"\"\n",
    "    image = np.asarray(image)\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvssaSdu6u2U"
   },
   "outputs": [],
   "source": [
    "model = hub.load(SAVED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDv63K_W9anN"
   },
   "outputs": [],
   "source": [
    "folder_path = '/content/test_images/test_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psYmfQkS3it8"
   },
   "source": [
    "Create output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rB9-qdHOCg6m"
   },
   "outputs": [],
   "source": [
    "os.mkdir('/content/output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTN4qnoxHugd"
   },
   "outputs": [],
   "source": [
    "pipeline_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1710999793090,
     "user": {
      "displayName": "Suhail Hussain",
      "userId": "01084270938039820503"
     },
     "user_tz": -330
    },
    "id": "nBO_zKFwiNxb",
    "outputId": "9f3e9fc2-fa4b-4864-f309-ac985a9ef653"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00c7f84d61adce05.jpg',\n",
       " '0c2b594e8d66de4c.jpg',\n",
       " '00bedd5c2fbf2dff.jpg',\n",
       " '03a1e7cf965c52c3.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90616,
     "status": "ok",
     "timestamp": 1711000090255,
     "user": {
      "displayName": "Suhail Hussain",
      "userId": "01084270938039820503"
     },
     "user_tz": -330
    },
    "id": "XZGnOW0m-7lD",
    "outputId": "35b246eb-45b5-447c-826a-aa26254a07b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE NAME:  00c7f84d61adce05\n",
      "Time Taken: 24.691547\n",
      "==================================\n",
      "Extracted Text:\n",
      "['fr', 'ret', 'Ef', 'ht']\n",
      "===================================\n",
      "IMAGE NAME:  0c2b594e8d66de4c\n",
      "Time Taken: 27.638587\n",
      "==================================\n",
      "Extracted Text:\n",
      "['', 'Bertolt', 'Brecht', '', 'Der', 'kaukasischd', 'Kreidekreis', '', 'edition', 'suhrkamp']\n",
      "===================================\n",
      "IMAGE NAME:  00bedd5c2fbf2dff\n",
      "Time Taken: 19.321335\n",
      "==================================\n",
      "Extracted Text:\n",
      "['E', 'TALK', 'IS', 'CHEAP', 'REALLY']\n",
      "===================================\n",
      "IMAGE NAME:  03a1e7cf965c52c3\n",
      "Time Taken: 17.512483\n",
      "==================================\n",
      "Extracted Text:\n",
      "['1assic', 'Sinat', 'ra', 'SEI', 'li', 'ae', '', '', 'Get', 'a', 'Kick', 'Out', 'of', 'hoy', 'They', 'Cant', 'Take', 'That', 'NEA', 'g', 'You', 'Make', 'Me', 'Feel', 'So', 'Young', 'Oey', 'iy', 'Fly', 'babi', 'Wit']\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "for image_file_name in os.listdir(folder_path):\n",
    "    image_name = image_file_name.split('.')[0]\n",
    "    image_path = folder_path + image_file_name\n",
    "\n",
    "    if image_name is None or image_name == '':\n",
    "      continue\n",
    "\n",
    "    print(f'IMAGE NAME: ', image_name)\n",
    "    start = time.time()\n",
    "\n",
    "    result_image = detect_text_east(image_path)\n",
    "    #display_image(result_image)\n",
    "    output_path = f'/content/output/{image_name}_stage_1.jpg'\n",
    "    status = cv2.imwrite(output_path, result_image)\n",
    "\n",
    "    ## SUPER RESOLUTION\n",
    "    IMAGE_PATH = f'/content/output/{image_name}_stage_1.jpg'\n",
    "    hr_image = preprocess_image(IMAGE_PATH)\n",
    "    #plot_image(tf.squeeze(hr_image), title=\"Original Image\")\n",
    "\n",
    "    fake_image = model(hr_image)\n",
    "    fake_image = tf.squeeze(fake_image)\n",
    "\n",
    "    #plot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\n",
    "    save_image(tf.squeeze(fake_image), filename=f\"/content/output/{image_name}_stage_2.jpg\")\n",
    "\n",
    "    ##OCR\n",
    "\n",
    "    masked_image_path = f'/content/output/{image_name}_stage_2.jpg'\n",
    "    #masked_image_path = '/content/test_images/00bedd5c2fbf2dff.jpg'\n",
    "\n",
    "    # Read the image using OpenCV (PyTesseract also works with PIL images)\n",
    "    masked_image = cv2.imread(masked_image_path)\n",
    "\n",
    "    # Convert the image to RGB (PyTesseract expects images in RGB format)\n",
    "    masked_image_rgb = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use PyTesseract to extract text\n",
    "    extracted_text = pytesseract.image_to_string(masked_image_rgb)\n",
    "\n",
    "    words = extracted_text.split()\n",
    "    words = [re.sub(r'[^\\w\\s]', '', word) for word in words]\n",
    "\n",
    "\n",
    "    print(\"Time Taken: %f\" % (time.time() - start))\n",
    "\n",
    "    print('==================================')\n",
    "    print(\"Extracted Text:\")\n",
    "    print(words)\n",
    "    pipeline_dict[image_name] = words\n",
    "    print('===================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoLIjZ_98MVa"
   },
   "outputs": [],
   "source": [
    "#!rm -r /content/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnBttu6wH6iv"
   },
   "outputs": [],
   "source": [
    "tesseract_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3235,
     "status": "ok",
     "timestamp": 1711000116308,
     "user": {
      "displayName": "Suhail Hussain",
      "userId": "01084270938039820503"
     },
     "user_tz": -330
    },
    "id": "3a-prlc0Eki_",
    "outputId": "95e4e870-d1b2-4f2d-f1b8-84a26711f41d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: 00c7f84d61adce05\n",
      "Time Taken: 0.724563\n",
      "==================================\n",
      "Extracted Text:\n",
      "[]\n",
      "===================================\n",
      "Image Name: 0c2b594e8d66de4c\n",
      "Time Taken: 0.787491\n",
      "==================================\n",
      "Extracted Text:\n",
      "['Bertolt', 'Brecht', 'Der', 'kaukasische', 'Kreidekreis', 'edition', 'suhrkamp', 'SV', 'sea', '2S']\n",
      "===================================\n",
      "Image Name: 00bedd5c2fbf2dff\n",
      "Time Taken: 0.540817\n",
      "==================================\n",
      "Extracted Text:\n",
      "['', 'VACANCY']\n",
      "===================================\n",
      "Image Name: 03a1e7cf965c52c3\n",
      "Time Taken: 0.695706\n",
      "==================================\n",
      "Extracted Text:\n",
      "['Classic', 'Sinatra', 'Come', 'Fly', 'With', 'Me', 'Petes', 'Ue', 'eee', 'eae', 'ace', 'Esty', 'SONY', '', 'le', 'ETS', 'aR', 'ETT', 'ae', 'His', '', 'TTS', 'Wis', 'meek', 'Te', 'They', 'Cant', 'Take', 'That', 'Away', 'fr', 'You', 'Make', 'Me', 'Feel', 'So', 'ome', 'FY', 'Wa']\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "for image_file_name in os.listdir(folder_path):\n",
    "    start = time.time()\n",
    "\n",
    "    image_name = image_file_name.split('.')[0]\n",
    "    image_path = folder_path + image_file_name\n",
    "\n",
    "    print(f'Image Name: {image_name}')\n",
    "\n",
    "    if image_name is None or image_name == '':\n",
    "      continue\n",
    "    masked_image_path = image_path\n",
    "    #masked_image_path = '/content/test_images/00bedd5c2fbf2dff.jpg'\n",
    "\n",
    "    # Read the image using OpenCV (PyTesseract also works with PIL images)\n",
    "    masked_image = cv2.imread(masked_image_path)\n",
    "\n",
    "    # Convert the image to RGB (PyTesseract expects images in RGB format)\n",
    "    masked_image_rgb = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use PyTesseract to extract text\n",
    "    extracted_text = pytesseract.image_to_string(masked_image_rgb)\n",
    "\n",
    "    words = extracted_text.split()\n",
    "    words = [re.sub(r'[^\\w\\s]', '', word) for word in words]\n",
    "\n",
    "    print(\"Time Taken: %f\" % (time.time() - start))\n",
    "\n",
    "    print('==================================')\n",
    "    print(\"Extracted Text:\")\n",
    "    print(words)\n",
    "    print('===================================')\n",
    "\n",
    "    tesseract_dict[image_name] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FEejliOJvU6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
